{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MMagic Inference Tutorial\n",
    "\n",
    "Welcome to MMagic! This is the official tutorial for using MMagic inference api to predict your own image or video.\n",
    "\n",
    "In this tutorial, you will learn how to\n",
    "\n",
    "[1. Install MMagic](#1-install-mmagic)\n",
    "\n",
    "[2. Check inference supported tasks and models](#2-check-inference-supported-tasks-and-models)\n",
    "\n",
    "[3. Perform inference using MMagic\n",
    " inference API](#3-perform-inference-with-mmagic-api)\n",
    "\n",
    "&emsp; [3.1 Prepare some images or videos for inference](#31-prepare-some-images-or-videos-for-inference)\n",
    "\n",
    "&emsp; [3.2 Perform inference with two lines of python code](#32-perform-inference-with-two-lines-of-python-code)\n",
    "\n",
    "&emsp; [3.3 Infer with different settings of a specific model](#33-infer-with-different-settings-of-a-specific-model)\n",
    "\n",
    "&emsp; [3.4 Infer with extra parameters](#34-inference-with-extra-parameters)\n",
    "\n",
    "[4. Perform inference with models of different tasks including](#4-perform-inference-with-models-of-different-tasks):\n",
    "\n",
    "&emsp; [4.1 Inference of conditional GANs models](#41-inference-of-conditional-gan-models)\n",
    "\n",
    "&emsp; [4.2 Inference of inpanting models](#42-inference-of-inpainting-models)\n",
    "\n",
    "&emsp; [4.3 Inference of matting models](#43-inference-of-matting-models)\n",
    "\n",
    "&emsp; [4.4 Inference of super resolution models](#44-inference-of-image-super-resolution-models)\n",
    "\n",
    "&emsp; [4.5 Inference of image2image models](#45-inference-of-image-translation-models)\n",
    "\n",
    "&emsp; [4.6 Inference of unconditional GANs models](#46-inference-of-unconditional-gan-models)\n",
    "\n",
    "&emsp; [4.7 Inference of video interpolation models](#47-inference-of-video-interpolation-models)\n",
    "\n",
    "&emsp; [4.8 Inference of video super resolution models](#48-inference-of-video-restoration-models)\n",
    "\n",
    "&emsp; [4.9 Inference of text-to-image models](#49-inference-of-text-to-image-models)\n",
    "\n",
    "Let's start!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Install MMagic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# Check PyTorch version\n",
    "!pip3 list | grep torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# Install mmcv dependency via openmim\n",
    "!pip3 install openmim\n",
    "!mim install 'mmcv>=2.0.0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# Install mmagic from source\n",
    "%cd ..\n",
    "!pip3 install -e .\n",
    "%cd demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check MMagic installation\n",
    "import mmagic\n",
    "print(mmagic.__version__)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Check inference supported tasks and models\n",
    "\n",
    "There are multiple task types in MMagic: Matting, Inpainting, Video Super-Resolution, Image Super-Resolution, Image2Image, Unconditional GANs, Conditional GANs, Video Interpolation. \n",
    "\n",
    "We provide some models for each task. All available models and tasks could be printed out like this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmagic.apis import MMagicInferencer\n",
    "\n",
    "# print all supported models for inference.\n",
    "inference_supported_models = MMagicInferencer.get_inference_supported_models()\n",
    "print('all supported models:')\n",
    "print(inference_supported_models)\n",
    "\n",
    "# print all supported tasks for inference.\n",
    "supported_tasks = MMagicInferencer.get_inference_supported_tasks()\n",
    "print('all supported tasks:')\n",
    "print(supported_tasks)\n",
    "\n",
    "# print all supported models for one task, take image translation for example.\n",
    "task_supported_models = MMagicInferencer.get_task_supported_models('Image2Image')\n",
    "print('translation models:')\n",
    "print(task_supported_models)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Perform inference with MMagic API\n",
    "\n",
    "Next we describe how to perform inference with python code snippets.\n",
    "\n",
    "(We also provide command line interface for you to do inference by running mmagic_inference_demo.py. The usage of this interface could be found in [README.md](./README.md) and more guidance could be found in the [documentation](https://mmagic.readthedocs.io/en/latest/user_guides/3_inference.html#).)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Prepare some images or videos for inference\n",
    "\n",
    "Before we start to perform inference with a pretrained model, some input images or videos should be prepared. \n",
    "\n",
    "Take image translation for example. We need a input image to be translated.\n",
    "\n",
    "Put your image to some directory and make a directory to save processed image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# make a dir for input image and output image\n",
    "!mkdir -p ./../resources/input/translation\n",
    "!mkdir -p ./../resources/output/translation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also have prepared some images and videos for you. You can download by running [download_inference_resouces.py](./download_inference_resources.py).\n",
    "\n",
    "This script allows you to see what resources are available and makes download easier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# see all resources\n",
    "!python download_inference_resources.py --print-all\n",
    "# see all task types\n",
    "!python download_inference_resources.py --print-task-type\n",
    "# see resources of one specific task\n",
    "!python download_inference_resources.py --print-task 'Inpainting'\n",
    "# download all resouces to default dir '../resources'\n",
    "!python download_inference_resources.py\n",
    "# download resouces of one task\n",
    "!python download_inference_resources.py --task 'Inpainting'\n",
    "# download to the directory you want\n",
    "!python download_inference_resources.py --root-dir '../resources'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Perform inference with two lines of python code. \n",
    "\n",
    "There are two steps:\n",
    "\n",
    "First, create a MMagicInferencer instance by a pretrained model name.\n",
    "\n",
    "Second, infer your own image with this MMagicInferencer instance. The translated image will be saved to result_out_dir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmagic.apis import MMagicInferencer\n",
    "\n",
    "# Create a MMagicInferencer instance\n",
    "editor = MMagicInferencer('pix2pix')\n",
    "# Infer a image. Input image path and output image path is needed.\n",
    "results = editor.infer(img='../resources/input/translation/gt_mask_0.png', result_out_dir='../resources/output/translation/tutorial_translation_pix2pix_res.jpg')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You could see your result image by plotting it out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the result image\n",
    "import mmcv\n",
    "import matplotlib.pyplot as plt \n",
    "img = mmcv.imread('../resources/output/translation/tutorial_translation_pix2pix_res.jpg')\n",
    "plt.imshow(mmcv.bgr2rgb(img))\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Infer with different settings of a specific model\n",
    "\n",
    "There are some different configs and checkpoints for one model.\n",
    "\n",
    "Take conditional GAN model 'biggan' as an example. We have pretrained model for Cifar and Imagenet, and all pretrained models of 'biggan' are listed in its [metafile.yaml](../configs/biggan/metafile.yml)\n",
    "\n",
    "You could configure different settings by passing 'model_setting' to 'MMagicInferencer'. Every model's default setting is 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mmcv\n",
    "import matplotlib.pyplot as plt\n",
    "from mmagic.apis import MMagicInferencer\n",
    "\n",
    "result_out_dir = '../resources/output/conditional/tutorial_conditinal_biggan_res_setting1.jpg'\n",
    "# configure setting to 1\n",
    "editor = MMagicInferencer('biggan', model_setting=1) \n",
    "results = editor.infer(label=1, result_out_dir=result_out_dir)\n",
    "\n",
    "# plot the result image\n",
    "img = mmcv.imread(result_out_dir)\n",
    "plt.imshow(mmcv.bgr2rgb(img))\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Infer with extra parameters\n",
    "\n",
    "Some models may have extra parameters that could be configured to perform inference.\n",
    "\n",
    "Take 'biggan' for example. You could configure 'num_batches' in a dict and pass it to 'MMagicInferencer'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mmcv\n",
    "import matplotlib.pyplot as plt\n",
    "from mmagic.apis import MMagicInferencer\n",
    "\n",
    "result_out_dir = '../resources/output/conditional/tutorial_conditinal_biggan_res_sample6.jpg'\n",
    "# use a dict to pass the parameters, num_batches means images output num for one inference\n",
    "editor = MMagicInferencer('biggan', model_setting=1, extra_parameters={'num_batches':6}) \n",
    "results = editor.infer(label=1, result_out_dir=result_out_dir)\n",
    "\n",
    "# plot the result image and we could see 6 images in a inference batch\n",
    "img = mmcv.imread(result_out_dir)\n",
    "plt.imshow(mmcv.bgr2rgb(img))\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To know what extra parameters that a model have, do like this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmagic.apis import MMagicInferencer\n",
    "\n",
    "editor = MMagicInferencer('biggan', model_setting=1) \n",
    "editor.print_extra_parameters()\n",
    "# 'num_batches' and 'sample_model' are extra parameters in 'biggan' model."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Perform inference with models of different tasks"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Inference of conditional GAN models\n",
    "\n",
    "Conditional GAN models take a label as input and output a image. We take 'biggan' as an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mmcv\n",
    "import matplotlib.pyplot as plt \n",
    "from mmagic.apis import MMagicInferencer\n",
    "\n",
    "# Create a MMagicInferencer instance and infer\n",
    "result_out_dir = '../resources/output/conditional/tutorial_conditinal_biggan_res.jpg'\n",
    "editor = MMagicInferencer('biggan', model_setting=1)\n",
    "results = editor.infer(label=1, result_out_dir=result_out_dir)\n",
    "\n",
    "# plot the result image\n",
    "img = mmcv.imread(result_out_dir)\n",
    "plt.imshow(mmcv.bgr2rgb(img))\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Inference of inpainting models\n",
    "\n",
    "Inpaiting models take a masked image and mask pair as input, and output a inpainted image. We take 'global_local' as an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mmcv\n",
    "import matplotlib.pyplot as plt \n",
    "from mmagic.apis import MMagicInferencer\n",
    "\n",
    "img = '../resources/input/inpainting/celeba_test.png'\n",
    "mask = '../resources/input/inpainting/bbox_mask.png'\n",
    "\n",
    "# show input image and mask\n",
    "input_img = mmcv.imread(img)\n",
    "plt.imshow(mmcv.bgr2rgb(input_img))\n",
    "plt.show()\n",
    "input_mask = mmcv.imread(mask)\n",
    "plt.imshow(mmcv.bgr2rgb(input_mask))\n",
    "plt.show()\n",
    "\n",
    "# Create a MMagicInferencer instance and infer\n",
    "result_out_dir = '../resources/output/inpainting/tutorial_inpainting_global_local_res.jpg'\n",
    "editor = MMagicInferencer('global_local', model_setting=1)\n",
    "results = editor.infer(img=img, mask=mask, result_out_dir=result_out_dir)\n",
    "\n",
    "# plot the result image\n",
    "img = mmcv.imread(result_out_dir)\n",
    "plt.imshow(mmcv.bgr2rgb(img))\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Inference of matting models\n",
    "\n",
    "Inpaiting models take a image and trimap pair as input, and output a alpha image. We take 'gca' as an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mmcv\n",
    "import matplotlib.pyplot as plt \n",
    "from mmagic.apis import MMagicInferencer\n",
    "\n",
    "img = '../resources/input/matting/GT05.jpg'\n",
    "trimap = '../resources/input/matting/GT05_trimap.jpg'\n",
    "\n",
    "# show input image and mask\n",
    "input_img = mmcv.imread(img)\n",
    "plt.imshow(mmcv.bgr2rgb(input_img))\n",
    "plt.show()\n",
    "input_trimap = mmcv.imread(trimap)\n",
    "plt.imshow(mmcv.bgr2rgb(input_trimap))\n",
    "plt.show()\n",
    "\n",
    "# Create a MMagicInferencer instance and infer\n",
    "result_out_dir = '../resources/output/matting/tutorial_matting_gca_res.png'\n",
    "editor = MMagicInferencer('gca')\n",
    "results = editor.infer(img=img, trimap=trimap, result_out_dir=result_out_dir)\n",
    "\n",
    "# plot the result image\n",
    "img = mmcv.imread(result_out_dir)\n",
    "plt.imshow(mmcv.bgr2rgb(img))\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Inference of image super resolution models\n",
    "\n",
    "Image super resolution models take a image as input, and output a high resolution image. We take 'esrgan' as an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mmcv\n",
    "import matplotlib.pyplot as plt \n",
    "from mmagic.apis import MMagicInferencer\n",
    "\n",
    "# Create a MMagicInferencer instance and infer\n",
    "img = '../resources/input/restoration/0901x2.png'\n",
    "result_out_dir = '../resources/output/restoration/tutorial_restoration_esrgan_res.png'\n",
    "editor = MMagicInferencer('esrgan')\n",
    "results = editor.infer(img=img, result_out_dir=result_out_dir)\n",
    "\n",
    "# plot the result image\n",
    "img = mmcv.imread(result_out_dir)\n",
    "plt.imshow(mmcv.bgr2rgb(img))\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5 Inference of image translation models\n",
    "\n",
    "Image translation models take a image as input, and output a translated image. We take 'pix2pix' as an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mmcv\n",
    "import matplotlib.pyplot as plt \n",
    "from mmagic.apis import MMagicInferencer\n",
    "\n",
    "img = '../resources/input/translation/gt_mask_0.png'\n",
    "\n",
    "# show input image and mask\n",
    "input_img = mmcv.imread(img)\n",
    "plt.imshow(mmcv.bgr2rgb(input_img))\n",
    "plt.show()\n",
    "\n",
    "# Create a MMagicInferencer instance and infer\n",
    "result_out_dir = '../resources/output/translation/tutorial_translation_pix2pix_res.png'\n",
    "editor = MMagicInferencer('pix2pix')\n",
    "results = editor.infer(img=img, result_out_dir=result_out_dir)\n",
    "\n",
    "# plot the result image\n",
    "img = mmcv.imread(result_out_dir)\n",
    "plt.imshow(mmcv.bgr2rgb(img))\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.6 Inference of unconditional GAN models\n",
    "\n",
    "Unconditional GAN models do not need input, and output a image. We take 'styleganv1' as an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mmcv\n",
    "import matplotlib.pyplot as plt \n",
    "from mmagic.apis import MMagicInferencer\n",
    "\n",
    "# Create a MMagicInferencer instance and infer\n",
    "result_out_dir = '../resources/output/unconditional/tutorial_unconditional_styleganv1_res.png'\n",
    "editor = MMagicInferencer('styleganv2')\n",
    "results = editor.infer(result_out_dir=result_out_dir)\n",
    "\n",
    "# plot the result image\n",
    "img = mmcv.imread(result_out_dir)\n",
    "plt.imshow(mmcv.bgr2rgb(img))\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.7 Inference of video interpolation models\n",
    "\n",
    "Video interpolation models take a video as input, and output a interpolated video. We take 'flavr' as an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from mmagic.apis import MMagicInferencer\n",
    "from mmengine import mkdir_or_exist\n",
    "\n",
    "# Create a MMagicInferencer instance and infer\n",
    "video = '../resources/input/video_interpolation/b-3LLDhc4EU_000000_000010.mp4'\n",
    "result_out_dir = '../resources/output/video_interpolation/tutorial_video_interpolation_flavr_res.mp4'\n",
    "mkdir_or_exist(os.path.dirname(result_out_dir))\n",
    "editor = MMagicInferencer('flavr')\n",
    "results = editor.infer(video=video, result_out_dir=result_out_dir)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please check the result video in the output directory."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.8 Inference of video restoration models\n",
    "\n",
    "Video restoration models take a video as input, and output a restorated video. We take 'basicvsr' as an example.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from mmagic.apis import MMagicInferencer\n",
    "from mmengine import mkdir_or_exist\n",
    "\n",
    "# Create a MMagicInferencer instance and infer\n",
    "video = '../resources/input/video_restoration/QUuC4vJs_000084_000094_400x320.mp4'\n",
    "result_out_dir = '../resources/output/video_restoration/tutorial_video_restoration_edvr_res.mp4'\n",
    "mkdir_or_exist(os.path.dirname(result_out_dir))\n",
    "editor = MMagicInferencer('edvr', extra_parameters={'window_size':5})\n",
    "results = editor.infer(video=video, result_out_dir=result_out_dir)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please check the result video in the output directory."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.9 Inference of text-to-image models\n",
    "\n",
    "Text-to-image models take text as input, and output a image. We take 'stable_diffusion' as an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mmcv\n",
    "import matplotlib.pyplot as plt \n",
    "from mmagic.apis import MMagicInferencer\n",
    "\n",
    "# Create a MMagicInferencer instance and infer\n",
    "editor = MMagicInferencer(model_name='stable_diffusion')\n",
    "text_prompts = 'A panda is having dinner at KFC'\n",
    "result_out_dir = '../resources/output/text2image/tutorial_text2image_sd_res.png'\n",
    "editor.infer(text=text_prompts, result_out_dir=result_out_dir)\n",
    "\n",
    "# plot the result image\n",
    "img = mmcv.imread(result_out_dir)\n",
    "plt.imshow(mmcv.bgr2rgb(img))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mmagic",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2396e09a98edfab6266f814c68e2f319a2f52e823b3715487b27762471d9be4e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
